{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "lq1NtBybtlqx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "from keras.applications import VGG16\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjwjB2XZt6mw"
      },
      "source": [
        "# Завантаження датасету Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kZ4FccBrt-53"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Розмір зображень, що будуть використовуватись в моделі"
      ],
      "metadata": {
        "id": "pckv3OtGfYQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (32, 32)"
      ],
      "metadata": {
        "id": "clWVhnQIfas0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcDMZvXJuPtS"
      },
      "source": [
        "# Зміна розмірності зображень та повторення каналів"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mjjZfcEPuS8X"
      },
      "outputs": [],
      "source": [
        "train_images = tf.image.resize(train_images[..., np.newaxis], image_size)\n",
        "train_images = np.repeat(train_images, 3, axis=-1)\n",
        "test_images = tf.image.resize(test_images[..., np.newaxis], image_size)\n",
        "test_images = np.repeat(test_images, 3, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Масштабування пікселів до діапазону [0, 1]"
      ],
      "metadata": {
        "id": "XMJh6LYPfojx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.array(train_images) / 255.0\n",
        "test_images = np.array(test_images) / 255.0"
      ],
      "metadata": {
        "id": "2FPRIDVvfsuk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Кількість класів"
      ],
      "metadata": {
        "id": "58q2ANA_fw6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10"
      ],
      "metadata": {
        "id": "yEVjpD-Kfy_l"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Перетворення міток в бінарний формат"
      ],
      "metadata": {
        "id": "pZUUQYPIf24n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)"
      ],
      "metadata": {
        "id": "3oMpt6j7f6mN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завантаження базової моделі VGG16 без верхніх повнозв'язних шарів та ваг"
      ],
      "metadata": {
        "id": "cQPDkCZ8f9ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_base = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(image_size[0], image_size[1], 3)\n",
        "    )"
      ],
      "metadata": {
        "id": "CZplRDqSf_u2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Заморожування базової моделі VGG16, щоб не навчати її ваги"
      ],
      "metadata": {
        "id": "fJJPnY3VgJp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_base.trainable = False"
      ],
      "metadata": {
        "id": "8NitcgRmgLvE"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EDL95xKucsJ"
      },
      "source": [
        "# Будуємо модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "BqA4swVQukDs"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(vgg_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTljydwqu1Y4"
      },
      "source": [
        "# Компіляція моделі"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "CzKOtwWju5GI"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "              )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QayHJ_cmvAqa"
      },
      "source": [
        "# Навчання моделі"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFHw-pwtvEM8",
        "outputId": "d7014d94-8d58-4f3f-db90-6fa5ccb77163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "938/938 [==============================] - 882s 939ms/step - loss: 0.5513 - accuracy: 0.8032 - val_loss: 0.4488 - val_accuracy: 0.8364\n",
            "Epoch 2/20\n",
            "938/938 [==============================] - 881s 939ms/step - loss: 0.4182 - accuracy: 0.8456 - val_loss: 0.4031 - val_accuracy: 0.8522\n",
            "Epoch 3/20\n",
            "938/938 [==============================] - 877s 935ms/step - loss: 0.3859 - accuracy: 0.8568 - val_loss: 0.3888 - val_accuracy: 0.8581\n",
            "Epoch 4/20\n",
            "938/938 [==============================] - 872s 929ms/step - loss: 0.3637 - accuracy: 0.8651 - val_loss: 0.3832 - val_accuracy: 0.8586\n",
            "Epoch 5/20\n",
            "938/938 [==============================] - 849s 906ms/step - loss: 0.3465 - accuracy: 0.8717 - val_loss: 0.3680 - val_accuracy: 0.8681\n",
            "Epoch 6/20\n",
            "938/938 [==============================] - 872s 930ms/step - loss: 0.3346 - accuracy: 0.8750 - val_loss: 0.3627 - val_accuracy: 0.8684\n",
            "Epoch 7/20\n",
            "938/938 [==============================] - 872s 930ms/step - loss: 0.3238 - accuracy: 0.8789 - val_loss: 0.3675 - val_accuracy: 0.8687\n",
            "Epoch 8/20\n",
            "938/938 [==============================] - 833s 888ms/step - loss: 0.3125 - accuracy: 0.8840 - val_loss: 0.3557 - val_accuracy: 0.8716\n",
            "Epoch 9/20\n",
            "938/938 [==============================] - 833s 889ms/step - loss: 0.3031 - accuracy: 0.8860 - val_loss: 0.3597 - val_accuracy: 0.8688\n",
            "Epoch 10/20\n",
            "938/938 [==============================] - 849s 906ms/step - loss: 0.2967 - accuracy: 0.8875 - val_loss: 0.3542 - val_accuracy: 0.8721\n",
            "Epoch 11/20\n",
            "938/938 [==============================] - 823s 877ms/step - loss: 0.2871 - accuracy: 0.8938 - val_loss: 0.3515 - val_accuracy: 0.8707\n",
            "Epoch 12/20\n",
            "938/938 [==============================] - 850s 906ms/step - loss: 0.2778 - accuracy: 0.8953 - val_loss: 0.3446 - val_accuracy: 0.8760\n",
            "Epoch 13/20\n",
            "938/938 [==============================] - 851s 908ms/step - loss: 0.2727 - accuracy: 0.8969 - val_loss: 0.3586 - val_accuracy: 0.8747\n",
            "Epoch 14/20\n",
            "938/938 [==============================] - 850s 906ms/step - loss: 0.2659 - accuracy: 0.8997 - val_loss: 0.3504 - val_accuracy: 0.8778\n",
            "Epoch 15/20\n",
            "938/938 [==============================] - 852s 908ms/step - loss: 0.2589 - accuracy: 0.9015 - val_loss: 0.3514 - val_accuracy: 0.8757\n",
            "Epoch 16/20\n",
            "938/938 [==============================] - 834s 889ms/step - loss: 0.2533 - accuracy: 0.9040 - val_loss: 0.3492 - val_accuracy: 0.8776\n",
            "Epoch 17/20\n",
            "938/938 [==============================] - 855s 912ms/step - loss: 0.2492 - accuracy: 0.9057 - val_loss: 0.3580 - val_accuracy: 0.8753\n",
            "Epoch 18/20\n",
            "938/938 [==============================] - 852s 909ms/step - loss: 0.2414 - accuracy: 0.9091 - val_loss: 0.3516 - val_accuracy: 0.8793\n",
            "Epoch 19/20\n",
            "938/938 [==============================] - 854s 911ms/step - loss: 0.2375 - accuracy: 0.9099 - val_loss: 0.3683 - val_accuracy: 0.8732\n",
            "Epoch 20/20\n",
            "938/938 [==============================] - 852s 909ms/step - loss: 0.2324 - accuracy: 0.9123 - val_loss: 0.3508 - val_accuracy: 0.8779\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(test_images, test_labels)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMWC9aopvVUH"
      },
      "source": [
        "# Оцінка точності моделі"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iHv39EVvadJ",
        "outputId": "4e75c66d-25ce-4a8f-fe0c-acaaf0d6509b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 123s 393ms/step - loss: 0.3508 - accuracy: 0.8779\n",
            "Точність на тестових даних: 87.79%\n"
          ]
        }
      ],
      "source": [
        "_, accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Точність на тестових даних: {accuracy * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ВИСНОВКИ:\n",
        "Отримана точність багатошарової мережі на тестових даних становить 92.41%.\n",
        "\n",
        "Порівнюючи цю точність з точністю згорткової мережі, яку ми навчали у поточному завданні, яка становила 87.79% на тестових даних, ми бачимо, що багатошарова  мережа показала кращі результати.\n",
        "\n",
        "Це може бути незвичайним, оскільки в загальному згорткові мережі, як правило, добре показуються на завданнях класифікації зображень.\n",
        "Також слід зазначити, що тренування згорткової мережі зайняло значно більше часу не зважаючи на меншу кількість епох."
      ],
      "metadata": {
        "id": "E48gw67RqYh-"
      }
    }
  ]
}